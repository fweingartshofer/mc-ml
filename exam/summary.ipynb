{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "## Types of Machine Learning\n",
    "### Supervised ML\n",
    "Each input has an explicit output, like a label or number.\n",
    "Its goal is to find relations between in- and output.\n",
    "\n",
    "The trained model can be used in an application.\n",
    "\n",
    "#### Classification\n",
    "Has labels as target (output), these are discrete values.\n",
    "Used to predict e.g.  genre of a song.\n",
    "\n",
    "#### Regression\n",
    "Output is a numeric continuous value, like stock prices.\n",
    "\n",
    "### Unsupervised ML\n",
    "No output, the goal is to find relations between samples, e.g. clustering.\n",
    "\n",
    "### Others\n",
    "- Reinforcement learning, use a reward function with an agent, actions in an environment (states) in a feedback-update-loop to continuously update the model.\n",
    "- Deep learning, deep neural networks, combines supervised, unsupervised and some other techniques\n",
    "\n",
    "## Glossary\n",
    "- Model: Relations in data that we model. In supervised learning: regression/classification model that is trained on our data.\n",
    "- Model type/class: The underlying algorithm that is used to create the model, like SVM or KNN.\n",
    "- Model parameters: Model parameters are what the models learn from data during training *on its own*\n",
    "- Hyperparameters: They are the parameters for the algorithm and influence\n",
    "    - how the model learns from the data\n",
    "    - the model's complexity. Hyperparameters can be tuned to change the models' behaviour.\n",
    "- Training: Fitting the model to the data.\n",
    "- Evaluation/Test: Check how the model performs on test data.\n",
    "- Features/Predictors/Dimensions: measurable property, usually the columns in a csv.\n",
    "- Sample: one data point or one row in a csv-file\n",
    "\n",
    "## Basic ML Workflow\n",
    "![Basic ML Workflow](img/ml_workflow.png)\n",
    "\n",
    "## Type III Error\n",
    "*Provide the right answer to the wrong question.*\n",
    "\n",
    "Often occurs when the dataset is not fully understood or some kind of pattern occurs in it, that does not occur naturally.\n",
    "For example, model learns that every second sample is of type `A`.\n",
    "\n",
    "Use common sense and intuition!\n",
    "\n",
    "[Some examples](https://docs.google.com/spreadsheets/u/1/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml?pli=1)\n",
    "\n",
    "# Visualization\n",
    "Visualization helps to understand data.\n",
    "It shows patterns in datasets.\n",
    "\n",
    "## What to look at first\n",
    "1. Before you even visualize anything, the basics: Size of dataframe? Datatypes? Class distributions? Basic stats per features? Is there data missing? (NA, etc?)\n",
    "2. Distribution of individual features: consider visualizing\n",
    "3. Relations between features: consider visualizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                  columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", 'target'])\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: iris.target_names[int(x)])\n",
    "df.shape  # the dimensions of the dataframe/dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes  # the datatype of each dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()  # shows for each numerical feature the mean, std, max, quantiles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification: class distribution\n",
    "Balanced data sets make things easier, but in reality often unequally distributed\n",
    "\n",
    "## Regression: distribution of target variable\n",
    "Similar problem: distribution not equal or does not cover complete target range\n",
    "\n",
    "## Scatterplot\n",
    "- pairplot, xyplot, etc\n",
    "- shows relations between 2 feature\n",
    "- Classification: color, symbol can indicate class label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "sn.scatterplot(df[[\"sepal_length\", \"sepal_width\", \"target\"]], x=\"sepal_length\", y=\"sepal_width\", hue=\"target\", ax=ax[0])\n",
    "sn.scatterplot(df[[\"petal_length\", \"petal_width\", \"target\"]], x=\"petal_length\", y=\"petal_width\", hue=\"target\", ax=ax[1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatterplot Matrix\n",
    "Can show correlation between features, but can be messy with high dimensional datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "for i, col in enumerate(df.drop(\"target\", axis=1).columns):\n",
    "    for j, inner_col in enumerate(df.drop(\"target\", axis=1).columns):\n",
    "        if col == inner_col:\n",
    "            ax[i, j].text(0.5, 0.5, col, ha='center', va='center', size=30)\n",
    "            break\n",
    "        sn.scatterplot(df[[col, inner_col, \"target\"]], x=col, y=inner_col, hue=\"target\", ax=ax[i, j])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Densityplot\n",
    "- Density of distribution of single variable\n",
    "- Sometimes plots individual samples with scatter for better understanding of data\n",
    "- Kernel parameter: defines granularity of density estimate\n",
    "- Classification: the more feature densities of different classes overlap, the more similar is the feature\n",
    "- Differences in density: feature poss. captures some differences in classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "for i, col in enumerate(df.drop(\"target\", axis=1)):\n",
    "    sn.kdeplot(df, x=col, hue=\"target\", ax=ax[i // 2, i % 2], kernel=\"\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Histogram\n",
    "Nr. of bins change how many bars are used in a histogram.\n",
    "See also: Binning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2)\n",
    "sn.histplot(df, x=\"sepal_length\", bins=4, ax=ax[0])\n",
    "sn.histplot(df, x=\"sepal_length\", bins=8, ax=ax[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean, Median, SD and MAD\n",
    "All can be used for feature derivation\n",
    "\n",
    "### Mean and Median\n",
    "Show the \"center\" of samples distribution.\n",
    "Median is considered more statistically robust(to outliers) than mean\n",
    "\n",
    "### SD and median absolut deviation (MAD)\n",
    "Shows the scatter of samples. Again MAD is more robust than SD.\n",
    "\n",
    "SD Formula:\n",
    "$$\n",
    "  SD=\\sqrt{\\frac{\\sum (x_{i}-\\mu)^2}{N}}\n",
    "$$\n",
    "\n",
    "MAD Formula:\n",
    "`X` is the series of samples.\n",
    "`m(X)` can be arithmetic mean, median or mode, but for median absolute deviation it is the median!\n",
    "\n",
    "$$\n",
    "  MAD=\\vert\\frac{1}{n}\\sum_{i=1}^n x_{i} - mean(X)\\vert\n",
    "$$\n",
    "\n",
    "**MEDIAN and MAD are not impacted by outliers!!!**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sn.displot(df, x=\"sepal_length\", kind=\"kde\", height=8)\n",
    "plt.axvline(x=df[\"sepal_length\"].mean(), color='black', label=\"mean\")\n",
    "plt.axvline(x=df[\"sepal_length\"].median(), color='red', label=\"median\")\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2)\n",
    "mean = df[\"sepal_length\"].mean()\n",
    "sd = df[\"sepal_length\"].std()\n",
    "median = df[\"sepal_length\"].median()\n",
    "mad = (df[\"sepal_length\"] - df[\"sepal_length\"].mean()).abs().mean()\n",
    "\n",
    "sn.kdeplot(df, x=\"sepal_length\", ax=ax[0])\n",
    "ax[0].axvline(x=mean, color='black', label=\"mean\")\n",
    "ax[0].axvline(x=mean + sd, color='green', label=\"sd\")\n",
    "ax[0].axvline(x=mean - sd, color='green')\n",
    "ax[0].legend(loc=0)\n",
    "\n",
    "sn.kdeplot(df, x=\"sepal_length\", ax=ax[1])\n",
    "ax[1].axvline(x=median, color='red', label=\"median\")\n",
    "ax[1].axvline(x=median + mad, color='blue', label=\"mad\")\n",
    "ax[1].axvline(x=median - mad, color='blue')\n",
    "ax[1].legend(loc=1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boxplot (=box-and-whisker-plot)\n",
    "Shows distribution of one variable as the variables quartiles.\n",
    "\n",
    "Quartiles != quantiles\n",
    "\n",
    "It's a form of quantiles using 3 separations that results into 4 parts.\n",
    "Each part holds ~25% of the data samples.\n",
    "- Q1: 25% below, 75% above\n",
    "- Q2: median, 50% below, 50% above\n",
    "- Q3: 75% below, 25% above\n",
    "\n",
    "There are also percentiles: if X is the 80% percentile -> 80% of samples below X\n",
    "\n",
    "The dots in a boxplot are the extrem outliers, the box contains 50% of the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2)\n",
    "df.boxplot(ax=ax[0])\n",
    "q = df[\"sepal_length\"].quantile([0.25, 0.5, 0.75])\n",
    "sn.kdeplot(df, x=\"sepal_length\", ax=ax[1])\n",
    "ax[1].axvline(x=q[0.25], color='blue', label=\"Q1\")\n",
    "ax[1].axvline(x=q[0.5], color='red', label=\"Q2\")\n",
    "ax[1].axvline(x=q[0.75], color='green', label=\"Q3\")\n",
    "ax[1].legend(loc=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: Levelplot / Contourplot: Visualization Page 40"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
