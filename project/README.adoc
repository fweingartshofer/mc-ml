:author: Fabian H., Lea S., Andreas W., Florian W.
:listing-caption: Listing
:source-highlighter: rouge
// path to the directory containing the source code
:src: ../

:toc:
:numbered:
:toclevels: 3
:rouge-style: github
:pdf-themesdir: ./doc/theme
:pdf-theme: basic
:pdf-fontsdir: ./doc/fonts
:half-width: pdfwidth=50%
// front-cover-image can be used to include the Exercise specification, for example:
//:front-cover-image: ./Exercise1.pdf

= Spotif-A.I: A spotify genre guesser

== Introduction

== Data Gathering

== Data preprocessing

== Data Visualization

== Model Training

=== Problems in first iteration

In our first iteration we couldn't manage to get any meaningful results.
We tried the following models with `GridSearchCV` to also include a hyperparameter search:

* tree.ExtraTreeClassifier
* neighbors.KNeighborsClassifier
* neural_network.MLPClassifier
* neighbors.RadiusNeighborsClassifier
* linear_model.RidgeClassifier

But the best we could achieve was an `accuracy` of `4%` with `19% precision`.

==== Target imbalance & too many targets

We think this was because of the massive data imbalance in our data. Where about `1/3`of our tags was `rock` and `1/4` pop.

.first iteration data imbalance
[.left]
image::doc/images/training/problems/massive-target-inbalance.png[{half-width}]

Although we had over `10.000` songs, we also had `4941` tags i.e. `4941` targets.
Which essentially means we either have too many tags or not enough songs.

It also didn't help, that some genres had multiple different naming schemes like `hip-hop` and`hip-hop`

==== Solution

We decided to try and resolve this by restricting our targets to the `top 10` appearing genres and wrap aggregate all other genres into a `misc` genre.

This was done by preprocessing the tags in our `mongoDB` and providing a view to download them. We also added some more songs.

.top 10 genres
image::doc/images/training/problems/aggregated-targets[]

=== Training

For the training of our tuned tags, we decided to use the following models and compare there performance:

* neighbors.KNeighborsClassifier
* tree.DecisionTreeClassifier
* ensemble.ExtraTreesClassifier
* neural_network.MLPClassifier

==== Feature Preprocessing

Like always, before we start training, we create a _held-back test set_ to use as a safety line and to perform the final evaluation of our model. +
However, before we can create the held-back test set, we need to use the `MultilabelBinarizer` to transform our targets (genre tags) into numerical values so that the models can work with them. +
For good measure we also use a `StandardScaler` to scale the input data for our models, as some models tend to perform better with this.

.held-back test set
[source, python]
----
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.preprocessing import StandardScaler

# transform tags with MultiLabelBinarizer
mlb = MultiLabelBinarizer()
y = mlb.fit_transform([*df['tags']])

X = df.drop(columns=['tags', 'artist_names', 'name', "artist_genres"])

# scale input
scaler = StandardScaler()
X = scaler.fit_transform(X)

# create held-back test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=234634754)  # 70/30 split
----


In order to train a `DecisionTreeClassifer`, we also needed to calculate the `class_weights` of our targets:

.class_weights calculation
[source, python]
----
import numpy as np
from collections import Counter
from sklearn.utils import class_weight
flat_labels = [label for sublist in df['tags'] for label in sublist]
label_counts = Counter(flat_labels)
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(flat_labels), y=flat_labels)
class_weights_dict = dict(zip(np.unique(flat_labels), class_weights))

# Create a list of class weight dictionaries for each label
class_weights_list = []
for i in range(y.shape[1]):
    label_column = y[:,i]
    label_counts = Counter(label_column)
    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(label_column), y=label_column)
    class_weights_list.append(dict(zip(np.unique(label_column), class_weights)))
class_weights_list
----

==== Feature Selection

Some models can't effectively use 1241 features, so for them, we need to reduce the amount of features. +
Other models like MLP however can use all features, so we do not throw away the other features

==== KNeighborsClassifier

==== DecisionTreeClassifier

==== ExtraTreesClassifier

==== MultilayerPerceptronClassifier

=== Results